{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRBDdr0SEqpT"
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xd57TRzExEr"
   },
   "source": [
    "**Assignment 4: Neural Networks**\n",
    "\n",
    "**Goal**: ​Get familiar with neural networks by implementing them and applying them to image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHNgWB1iFDu5"
   },
   "source": [
    "In this assignment we are going to learn about neural networks (NNs). The goal is to implement two neural networks: a fully-connected neural network, a convolutional neural network, and analyze their behavior.\n",
    "\n",
    "The considered task is image classification. We consider a dataset of small natural images (see the additional file) with multiple classes. We aim at formulating a model (a neural network) and learning it using the negative log-likelihood function (i.e., the cross-entropy loss) as the objective function, and the stochastic gradient descent as the optimizer.\n",
    "\n",
    "In this assignment, ​**the code must be implemented in PyTorch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jxgc7c--P0GH"
   },
   "source": [
    "## 1 Understanding the problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRteDLEPP3eX"
   },
   "source": [
    "The considered problem is about classifying images to $L$ classes. In the first part of the assignment, you are asked get familiar with PyTorch, a deep learning library, and the basics of neural networks, and implement neural-network-based classifiers. For this purpose, we will start with classifying small images (8px x 8px) of handwritten digits to one of 10 classes. The dataset is very small and all experiments could be achieved within a couple of minutes.\n",
    "\n",
    "In the second part, you are asked to implement the whole pipeline for a given dataset by yourself.\n",
    "\n",
    "Please run the code below and spend a while on analyzing the images.\n",
    "\n",
    "If any code line is unclear to you, please read on that in numpy, scipy, matplotlib and PyTorch docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g4wCnPRz-MaE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPS = 1.e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "id": "mRmwbuamRuge"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CLOUDSDK_CONFIG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-16cba3ea78c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# mount drive: WE NEED IT FOR SAVING IMAGES!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_env\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mhome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   root_dir = _os.path.realpath(\n\u001b[0;32m---> 43\u001b[0;31m       _os.path.join(_os.environ['CLOUDSDK_CONFIG'], '../..'))\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0minet_family\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'IPV4_ONLY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dev/fuse'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;31m# raise KeyError with the original key value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CLOUDSDK_CONFIG'"
     ]
    }
   ],
   "source": [
    "# IF YOU USE COLAB, THIS IS VERY USEFUL! OTHERWISE, PLEASE REMOVE IT.\n",
    "# mount drive: WE NEED IT FOR SAVING IMAGES!\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KEiEJE5sRvjc"
   },
   "outputs": [],
   "source": [
    "# IF YOU USE COLAB, THIS IS VERY USEFUL! OTHERWISE, PLEASE REMOVE IT.\n",
    "# PLEASE CHANGE IT TO YOUR OWN GOOGLE DRIVE!\n",
    "results_dir = '/content/gdrive/My Drive/Colab Notebooks/TEACHING/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Xm4e0Utl-30c"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# This is a class for the dataset of small (8px x 8px) digits.\n",
    "# Please try to understand in details how it works!\n",
    "class Digits(Dataset):\n",
    "  \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, mode='train', transforms=None):\n",
    "    digits = load_digits()\n",
    "    if mode == 'train':\n",
    "      self.data = digits.data[:1000].astype(np.float32)\n",
    "      self.targets = digits.target[:1000]\n",
    "    elif mode == 'val':\n",
    "      self.data = digits.data[1000:1350].astype(np.float32)\n",
    "      self.targets = digits.target[1000:1350]\n",
    "    else:\n",
    "      self.data = digits.data[1350:].astype(np.float32)\n",
    "      self.targets = digits.target[1350:]\n",
    "\n",
    "    self.transforms = transforms\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    sample_x = self.data[idx]\n",
    "    sample_y = self.targets[idx]\n",
    "    if self.transforms:\n",
    "      sample_x = self.transforms(sample_x)\n",
    "    return (sample_x, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bnDz_yGeuOnh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Here, we plot some images (8px x 8px).\n",
    "digits = load_digits()\n",
    "x = digits.data[:16].astype(np.float32)\n",
    "\n",
    "fig_data, axs = plt.subplots(4,4,figsize=(4, 4))\n",
    "fig_data.tight_layout()\n",
    "\n",
    "for i in range(4):\n",
    "  for j in range(4):\n",
    "    img = np.reshape(x[4*i+j],(8,8))\n",
    "    axs[i,j].imshow(img, cmap='gray')\n",
    "    axs[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgc_GFOyRBEi"
   },
   "source": [
    "## 2 Neural Networks for Digits (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDVf1vyORGUB"
   },
   "source": [
    "In this assignment, you are asked to implement a neural network (NN) classifier. Please take a look at the class below and fill in the missing parts.\n",
    "\n",
    "NOTE: Please pay attention to the inputs and outputs of each function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwuEfxSKpFtD"
   },
   "source": [
    "### 2.1 Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FThxxdkpKcQ"
   },
   "source": [
    "Below, we have two helper modules (layers) that can be used to reshape and flatten a tensor. They are useful for creating sequentials with convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5AB5Ch63Ak01"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# Here are two auxiliary functions that can be used for a convolutional NN (CNN).\n",
    "\n",
    "# This module reshapes an input (matrix -> tensor).\n",
    "class Reshape(nn.Module):\n",
    "  def __init__(self, size):\n",
    "    super(Reshape, self).__init__()\n",
    "    self.size = size # a list\n",
    "  \n",
    "  def forward(self, x):\n",
    "    assert x.shape[1] == np.prod(self.size)\n",
    "    return x.view(x.shape[0], *self.size)\n",
    "\n",
    "# This module flattens an input (tensor -> matrix) by blending dimensions \n",
    "# beyond the batch size.\n",
    "class Flatten(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Flatten, self).__init__()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3i9R3NmpUY3"
   },
   "source": [
    "Below is the main class for a classifier parameterized by a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vtv_pAkmOrS3"
   },
   "outputs": [],
   "source": [
    "#=========\n",
    "# GRADING:\n",
    "# 0 \n",
    "# 0.5 pt if code works but it is explained badly\n",
    "# 1.0 pt if code works and it is explained well\n",
    "#=========\n",
    "# Implement a neural network (NN) classifier. \n",
    "class ClassifierNeuralNet(nn.Module):\n",
    "    def __init__(self, classnet):\n",
    "        super(ClassifierNeuralNet, self).__init__()\n",
    "        # We provide a sequential module with layers and activations\n",
    "        self.classnet = classnet\n",
    "        # The loss function (the negative log-likelihood)\n",
    "        self.nll = nn.NLLLoss(reduction='none') #it requires log-softmax as input!!\n",
    "\n",
    "    # This function classifies an image x to a class.\n",
    "    # The output must be a class label (long).\n",
    "    def classify(self, x):\n",
    "      #------\n",
    "      # PLEASE FILL IN\n",
    "      # y_pred = ...\n",
    "      #------\n",
    "      return y_pred\n",
    "\n",
    "    # This function is crucial for a module in PyTorch.\n",
    "    # In our framework, this class outputs a value of the loss function.\n",
    "    def forward(self, x, y, reduction='avg'):\n",
    "      #------\n",
    "      # PLEASE FILL IN\n",
    "      # loss = ...\n",
    "      #------\n",
    "      if reduction == 'sum':\n",
    "        return loss.sum()\n",
    "      else:\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwaou1x-gmx3"
   },
   "source": [
    "**Question 1 (0-0.5pt):** What is the objective function for a classification task? In other words, what is nn.NLLLos in the code above? Pelase write it in mathematical terms.\n",
    "\n",
    "**Answer:**\n",
    "PLEASE FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvX88kN-irAD"
   },
   "source": [
    "**Question 2 (0-0.5pt):** In the code above, it is said to use the logarithm of the softmax as the final activation function. Is it correct to use the log-softmax instead of the softmax for making predictions (i.e., picking the most probable label).\n",
    "\n",
    "**Answer:** Yes, it is fine because the logarithm does not change the most probable label, it changes only the probability to the log-probability.\n",
    "\n",
    "PLEASE FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVqRQduw3mgm"
   },
   "source": [
    "### 2.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4g9uUFgYP1kT"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "  # If available, load the best performing model\n",
    "  if model_best is None:\n",
    "    model_best = torch.load(name + '.model')\n",
    "  \n",
    "  model_best.eval()# set the model to the evaluation mode\n",
    "  loss_test = 0.\n",
    "  loss_error = 0.\n",
    "  N = 0.\n",
    "  # start evaluation\n",
    "  for indx_batch, (test_batch, test_targets) in enumerate(test_loader):\n",
    "    # loss (nll)\n",
    "    loss_test_batch = model_best.forward(test_batch, test_targets, reduction='sum')\n",
    "    loss_test = loss_test + loss_test_batch.item()\n",
    "    # classification error\n",
    "    y_pred = model_best.classify(test_batch)\n",
    "    e = 1.*(y_pred == test_targets)\n",
    "    loss_error = loss_error + (1. - e).sum().item()\n",
    "    # the number of examples\n",
    "    N = N + test_batch.shape[0]\n",
    "  # divide by the number of examples\n",
    "  loss_test = loss_test / N\n",
    "  loss_error = loss_error / N\n",
    "\n",
    "  # Print the performance\n",
    "  if epoch is None:\n",
    "    print(f'-> FINAL PERFORMANCE: nll={loss_test}, ce={loss_error}')\n",
    "  else:\n",
    "    if epoch % 10 == 0:\n",
    "      print(f'Epoch: {epoch}, val nll={loss_test}, val ce={loss_error}')\n",
    "\n",
    "  return loss_test, loss_error\n",
    "\n",
    "# An auxiliary function for plotting the performance curves\n",
    "def plot_curve(name, signal, file_name='curve.pdf', xlabel='epochs', ylabel='nll', color='b-', test_eval=None):\n",
    "  # plot the curve\n",
    "  plt.plot(np.arange(len(signal)), signal, color, linewidth='3', label=ylabel +' val')\n",
    "  # if available, add the final (test) performance\n",
    "  if test_eval is not None:\n",
    "    plt.hlines(test_eval, xmin=0, xmax=len(signal), linestyles='dashed', label=ylabel +' test')\n",
    "    plt.text(len(signal), test_eval, \"{:.3f}\".format(test_eval),)\n",
    "  # set x- and ylabels, add legend, save the figure\n",
    "  plt.xlabel(xlabel), plt.ylabel(ylabel)\n",
    "  plt.legend()\n",
    "  plt.savefig(name + file_name, bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzRd-TiY3puF"
   },
   "source": [
    "### 2.3 Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMhQWbM1QcBM"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# The training procedure\n",
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "  nll_val = []\n",
    "  error_val = []\n",
    "  best_nll = 1000.\n",
    "  patience = 0\n",
    "\n",
    "  # Main training loop\n",
    "  for e in range(num_epochs):\n",
    "    model.train() # set the model to the training mode\n",
    "    # load batches\n",
    "    for indx_batch, (batch, targets) in enumerate(training_loader):\n",
    "      # calculate the forward pass (loss function for given images and labels)\n",
    "      loss = model.forward(batch, targets)\n",
    "      # remember we need to zero gradients! Just in case!\n",
    "      optimizer.zero_grad()\n",
    "      # calculate backward pass\n",
    "      loss.backward(retain_graph=True)\n",
    "      # run the optimizer\n",
    "      optimizer.step()\n",
    "\n",
    "    # Validation: Evaluate the model on the validation data\n",
    "    loss_e, error_e = evaluation(val_loader, model_best=model, epoch=e)\n",
    "    nll_val.append(loss_e)  # save for plotting\n",
    "    error_val.append(error_e)  # save for plotting\n",
    "\n",
    "    # Early-stopping: update the best performing model and break training if no \n",
    "    # progress is observed.\n",
    "    if e == 0:\n",
    "      torch.save(model, name + '.model')\n",
    "      best_nll = loss_e\n",
    "    else:\n",
    "      if loss_e < best_nll:\n",
    "        torch.save(model, name + '.model')\n",
    "        best_nll = loss_e\n",
    "        patience = 0\n",
    "      else:\n",
    "        patience = patience + 1\n",
    "\n",
    "    if patience > max_patience:\n",
    "      break\n",
    "\n",
    "  # Return nll and classification error.\n",
    "  nll_val = np.asarray(nll_val)\n",
    "  error_val = np.asarray(error_val)\n",
    "\n",
    "  return nll_val, error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHYGz3G87nuk"
   },
   "source": [
    "### 2.4 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op-YbN-JREqw"
   },
   "source": [
    "#### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_cRaP3gRET1"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Initialize training, validation and test sets.\n",
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "# Initialize data loaders.\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3ni_8Pv3iuG"
   },
   "source": [
    "#### Initialize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnMs4gcLRLEK"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Hyperparameters\n",
    "# -> data hyperparams\n",
    "D = 64   # input dimension\n",
    "\n",
    "# -> model hyperparams\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "K = 10 # the number of labels\n",
    "num_kernels = 32 #the number of kernels for CNN\n",
    "\n",
    "# -> training hyperparams\n",
    "lr = 1e-3 # learning rate\n",
    "wd = 1e-5 # weight decay\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VDyHP173vLF"
   },
   "source": [
    "#### Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9T9nXcE3xF2"
   },
   "source": [
    "In the code below, you are supposed to implement architectures for MLP and CNN. For properly implementing these architectures, you can get 0.5pt for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZH7ahwBRP9B"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE and FILL IN WHEN NECESSARY!\n",
    "# We will run two models: MLP and CNN\n",
    "names = ['classifier_mlp', 'classifier_cnn']\n",
    "\n",
    "# loop over models\n",
    "for name in names:\n",
    "  print('\\n-> START {}'.format(name))\n",
    "  # Create a folder (REMEMBER: You must mount your drive if you use Colab!)\n",
    "  if name == 'classifier_mlp':\n",
    "    name = name + '_M_' + str(M)\n",
    "  elif name == 'classifier_cnn':\n",
    "    name = name + '_M_' + str(M) + '_kernels_' + str(num_kernels)\n",
    "  \n",
    "  # Create a folder if necessary\n",
    "  result_dir = os.path.join(results_dir, 'results', name + '/')\n",
    "  if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "  # MLP\n",
    "  if name[0:14] == 'classifier_mlp':\n",
    "    #=========\n",
    "    # GRADING: \n",
    "    # 0\n",
    "    # 0.5pt if properly implemented\n",
    "    #=========\n",
    "    #------\n",
    "    # PLEASE FILL IN:\n",
    "    # classnet = nn.Sequential(...)\n",
    "    #\n",
    "    # You are asked here to propose your own architecture\n",
    "    # NOTE: Please remember that the output must be LogSoftmax!\n",
    "    #------\n",
    "\n",
    "  # CNN\n",
    "  elif name[0:14] == 'classifier_cnn':\n",
    "\n",
    "    #=========\n",
    "    # GRADING: \n",
    "    # 0\n",
    "    # 0.5pt if properly implemented\n",
    "    #=========\n",
    "    #------\n",
    "    # PLEASE FILL IN:\n",
    "    # classnet = nn.Sequential(...)\n",
    "    #\n",
    "    # You are asked here to propose your own architecture\n",
    "    # NOTE: Plese note that the images are represented as vectors, thus, you must\n",
    "    # use Reshape(size) as the first layer, and Flatten() after all convolutional\n",
    "    # layers and before linear layers.\n",
    "    # NOTE: Please remember that the output must be LogSoftmax!\n",
    "    #------\n",
    "\n",
    "  # Init ClassifierNN\n",
    "  model = ClassifierNeuralNet(classnet)\n",
    "\n",
    "  # Init OPTIMIZER (here we use ADAMAX)\n",
    "  optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr, weight_decay=wd) \n",
    "  \n",
    "  # Training procedure\n",
    "  nll_val, error_val = training(name=result_dir + name,\n",
    "                                max_patience=max_patience,\n",
    "                                num_epochs=num_epochs,\n",
    "                                model=model,\n",
    "                                optimizer=optimizer,\n",
    "                                training_loader=training_loader,\n",
    "                                val_loader=val_loader)\n",
    "  \n",
    "  # The final evaluation (on the test set)\n",
    "  test_loss, test_error = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "  # write the results to a file\n",
    "  f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "  f.write('NLL: ' + str(test_loss) + '\\nCE: ' + str(test_error))\n",
    "  f.close()\n",
    "  # create curves\n",
    "  plot_curve(result_dir + name, nll_val, file_name='_nll_val_curve.pdf', ylabel='nll', test_eval=test_loss)\n",
    "  plot_curve(result_dir + name, error_val, file_name='_ca_val_curve.pdf', ylabel='ce', color='r-', test_eval=test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFX-DzH9ftPg"
   },
   "source": [
    "## 2.5 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-TFtGdZfz3a"
   },
   "source": [
    "**Question 3 (0-0.5pt)**: Please compare the convergence of MLP and CNN in terms of the loss function and the classification error.\n",
    "\n",
    "**Answer**: PLEASE FILL IN and PASTE THE IMAGES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f2P57ZmlwXz"
   },
   "source": [
    "**Question 4 (0-0.5pt)**: In general, for a properly picked architectures, a CNN should work better than an MLP. Did you notice that? Why (in general) CNNs are better suited to images than MLPs?\n",
    "\n",
    "**Answer**: PLEASE FILL IN and PASTE THE IMAGES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QJ_mRdT7Ais"
   },
   "source": [
    "## 3 Application to Street House View Numbers (SVHN) (6pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHhUUaYL7GEx"
   },
   "source": [
    "Please repeat (some) of the code in the previous section and apply a bigger convolutional neural network (CNN) to the following dataset:\n",
    "\n",
    "http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Please follow the following steps:\n",
    "1. (1pt) Create appropriate Dataset class. Please remember to use the original training data and test data, and also to create a validation set from the traning data (at least 10% of the training examples). **Do not use extra examples!**\n",
    "2. (1pt) Implement an architecture that will give at most 0.1 classification error. For instance, see this paper as a reference: https://arxiv.org/pdf/1204.3968.pdf#:~:text=The%20SVHN%20classification%20dataset%20%5B8,set%20of%20more%20difficult%20samples\n",
    "3. (1pt) Think of an extra component that could improve the performance (e.g., a regularization, specific activation functions).\n",
    "4. (1pt) Provide a good explanation of the applied architecture and a description of all components.\n",
    "5. (2pt) Analyze the results.\n",
    "\n",
    "**Please be very precise, comment your code and provide a comprehensive and clear analysis.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
