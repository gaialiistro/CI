{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRBDdr0SEqpT"
   },
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xd57TRzExEr"
   },
   "source": [
    "**Assignment 4: Neural Networks**\n",
    "\n",
    "**Goal**: ​Get familiar with neural networks by implementing them and applying them to image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHNgWB1iFDu5"
   },
   "source": [
    "In this assignment we are going to learn about neural networks (NNs). The goal is to implement two neural networks: a fully-connected neural network, a convolutional neural network, and analyze their behavior.\n",
    "\n",
    "The considered task is image classification. We consider a dataset of small natural images (see the additional file) with multiple classes. We aim at formulating a model (a neural network) and learning it using the negative log-likelihood function (i.e., the cross-entropy loss) as the objective function, and the stochastic gradient descent as the optimizer.\n",
    "\n",
    "In this assignment, ​**the code must be implemented in PyTorch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jxgc7c--P0GH"
   },
   "source": [
    "## 1 Understanding the problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRteDLEPP3eX"
   },
   "source": [
    "The considered problem is about classifying images to $L$ classes. In the first part of the assignment, you are asked get familiar with PyTorch, a deep learning library, and the basics of neural networks, and implement neural-network-based classifiers. For this purpose, we will start with classifying small images (8px x 8px) of handwritten digits to one of 10 classes. The dataset is very small and all experiments could be achieved within a couple of minutes.\n",
    "\n",
    "In the second part, you are asked to implement the whole pipeline for a given dataset by yourself.\n",
    "\n",
    "Please run the code below and spend a while on analyzing the images.\n",
    "\n",
    "If any code line is unclear to you, please read on that in numpy, scipy, matplotlib and PyTorch docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g4wCnPRz-MaE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPS = 1.e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mRmwbuamRuge"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-16cba3ea78c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# IF YOU USE COLAB, THIS IS VERY USEFUL! OTHERWISE, PLEASE REMOVE IT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# mount drive: WE NEED IT FOR SAVING IMAGES!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# IF YOU USE COLAB, THIS IS VERY USEFUL! OTHERWISE, PLEASE REMOVE IT.\n",
    "# mount drive: WE NEED IT FOR SAVING IMAGES!\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KEiEJE5sRvjc"
   },
   "outputs": [],
   "source": [
    "# IF YOU USE COLAB, THIS IS VERY USEFUL! OTHERWISE, PLEASE REMOVE IT.\n",
    "# PLEASE CHANGE IT TO YOUR OWN GOOGLE DRIVE!\n",
    "results_dir = '//home/gaia/uni/CI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xm4e0Utl-30c"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# This is a class for the dataset of small (8px x 8px) digits.\n",
    "# Please try to understand in details how it works!\n",
    "class Digits(Dataset):\n",
    "  \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "  def __init__(self, mode='train', transforms=None):\n",
    "    digits = load_digits()\n",
    "    if mode == 'train':\n",
    "      self.data = digits.data[:1000].astype(np.float32)\n",
    "      self.targets = digits.target[:1000]\n",
    "    elif mode == 'val':\n",
    "      self.data = digits.data[1000:1350].astype(np.float32)\n",
    "      self.targets = digits.target[1000:1350]\n",
    "    else:\n",
    "      self.data = digits.data[1350:].astype(np.float32)\n",
    "      self.targets = digits.target[1350:]\n",
    "\n",
    "    self.transforms = transforms\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    sample_x = self.data[idx]\n",
    "    sample_y = self.targets[idx]\n",
    "    if self.transforms:\n",
    "      sample_x = self.transforms(sample_x)\n",
    "    return (sample_x, sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "from  pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bnDz_yGeuOnh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Here, we plot some images (8px x 8px).\n",
    "digits = load_digits()\n",
    "x = digits.data[:16].astype(np.float32)\n",
    "\n",
    "fig_data, axs = plt.subplots(4,4,figsize=(4, 4))\n",
    "fig_data.tight_layout()\n",
    "\n",
    "for i in range(4):\n",
    "  for j in range(4):\n",
    "    img = np.reshape(x[4*i+j],(8,8))\n",
    "    axs[i,j].imshow(img, cmap='gray')\n",
    "    axs[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgc_GFOyRBEi"
   },
   "source": [
    "## 2 Neural Networks for Digits (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDVf1vyORGUB"
   },
   "source": [
    "In this assignment, you are asked to implement a neural network (NN) classifier. Please take a look at the class below and fill in the missing parts.\n",
    "\n",
    "NOTE: Please pay attention to the inputs and outputs of each function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwuEfxSKpFtD"
   },
   "source": [
    "### 2.1 Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FThxxdkpKcQ"
   },
   "source": [
    "Below, we have two helper modules (layers) that can be used to reshape and flatten a tensor. They are useful for creating sequentials with convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5AB5Ch63Ak01"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# Here are two auxiliary functions that can be used for a convolutional NN (CNN).\n",
    "\n",
    "# This module reshapes an input (matrix -> tensor).\n",
    "class Reshape(nn.Module):\n",
    "  def __init__(self, size):\n",
    "    super(Reshape, self).__init__()\n",
    "    self.size = size # a list\n",
    "  \n",
    "  def forward(self, x):\n",
    "    assert x.shape[1] == np.prod(self.size)\n",
    "    return x.view(x.shape[0], *self.size)\n",
    "\n",
    "# This module flattens an input (tensor -> matrix) by blending dimensions \n",
    "# beyond the batch size.\n",
    "class Flatten(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Flatten, self).__init__()\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3i9R3NmpUY3"
   },
   "source": [
    "Below is the main class for a classifier parameterized by a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "Vtv_pAkmOrS3"
   },
   "outputs": [],
   "source": [
    "#=========\n",
    "# GRADING:\n",
    "# 0 \n",
    "# 0.5 pt if code works but it is explained badly\n",
    "# 1.0 pt if code works and it is explained well\n",
    "#=========\n",
    "# Implement a neural network (NN) classifier. \n",
    "class ClassifierNeuralNet(nn.Module):\n",
    "    def __init__(self, classnet):\n",
    "        super(ClassifierNeuralNet, self).__init__()\n",
    "        # We provide a sequential module with layers and activations\n",
    "        self.classnet = classnet\n",
    "        # The loss function (the negative log-likelihood)\n",
    "        self.nll = nn.NLLLoss(reduction='none') #it requires log-softmax as input!!\n",
    "\n",
    "    # This function classifies an image x to a class.\n",
    "    # The output must be a class label (long).\n",
    "    def classify(self, x):\n",
    "      #------        \n",
    "      y_pred = x.argmax(dim=1)\n",
    "      return y_pred\n",
    "\n",
    "    # This function is crucial for a module in PyTorch.\n",
    "    # In our framework, this class outputs a value of the loss function.\n",
    "    def forward(self, x, y, reduction='avg'):\n",
    "      #------\n",
    "      # PLEASE FILL IN\n",
    "      loss = self.nll(classnet(x), y)\n",
    "      if reduction == 'sum':\n",
    "        return loss.sum()\n",
    "      else:\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwaou1x-gmx3"
   },
   "source": [
    "**Question 1 (0-0.5pt):** What is the objective function for a classification task? In other words, what is nn.NLLLos in the code above? Pelase write it in mathematical terms.\n",
    "\n",
    "**Answer:**\n",
    "PLEASE FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvX88kN-irAD"
   },
   "source": [
    "**Question 2 (0-0.5pt):** In the code above, it is said to use the logarithm of the softmax as the final activation function. Is it correct to use the log-softmax instead of the softmax for making predictions (i.e., picking the most probable label).\n",
    "\n",
    "**Answer:** Yes, it is fine because the logarithm does not change the most probable label, it changes only the probability to the log-probability.\n",
    "\n",
    "PLEASE FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVqRQduw3mgm"
   },
   "source": [
    "### 2.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "4g9uUFgYP1kT"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "  # If available, load the best performing model\n",
    "  if model_best is None:\n",
    "    model_best = torch.load(name + '.model')\n",
    "  \n",
    "  model_best.eval()# set the model to the evaluation mode\n",
    "  loss_test = 0.\n",
    "  loss_error = 0.\n",
    "  N = 0.\n",
    "  # start evaluation\n",
    "  for indx_batch, (test_batch, test_targets) in enumerate(test_loader):\n",
    "    # loss (nll)\n",
    "    loss_test_batch = model_best.forward(test_batch, test_targets, reduction='sum')\n",
    "    loss_test = loss_test + loss_test_batch.item()\n",
    "    # classification error\n",
    "    y_pred = model_best.classify(test_batch)\n",
    "    e = 1.*(y_pred == test_targets)\n",
    "    loss_error = loss_error + (1. - e).sum().item()\n",
    "    # the number of examples\n",
    "    N = N + test_batch.shape[0]\n",
    "  # divide by the number of examples\n",
    "  loss_test = loss_test / N\n",
    "  loss_error = loss_error / N\n",
    "\n",
    "  # Print the performance\n",
    "  if epoch is None:\n",
    "    print(f'-> FINAL PERFORMANCE: nll={loss_test}, ce={loss_error}')\n",
    "  else:\n",
    "    if epoch % 10 == 0:\n",
    "      print(f'Epoch: {epoch}, val nll={loss_test}, val ce={loss_error}')\n",
    "\n",
    "  return loss_test, loss_error\n",
    "\n",
    "# An auxiliary function for plotting the performance curves\n",
    "def plot_curve(name, signal, file_name='curve.pdf', xlabel='epochs', ylabel='nll', color='b-', test_eval=None):\n",
    "  # plot the curve\n",
    "  plt.plot(np.arange(len(signal)), signal, color, linewidth='3', label=ylabel +' val')\n",
    "  # if available, add the final (test) performance\n",
    "  if test_eval is not None:\n",
    "    plt.hlines(test_eval, xmin=0, xmax=len(signal), linestyles='dashed', label=ylabel +' test')\n",
    "    plt.text(len(signal), test_eval, \"{:.3f}\".format(test_eval),)\n",
    "  # set x- and ylabels, add legend, save the figure\n",
    "  plt.xlabel(xlabel), plt.ylabel(ylabel)\n",
    "  plt.legend()\n",
    "  plt.savefig(name + file_name, bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzRd-TiY3puF"
   },
   "source": [
    "### 2.3 Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "CMhQWbM1QcBM"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE!\n",
    "# The training procedure\n",
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader):\n",
    "  nll_val = []\n",
    "  error_val = []\n",
    "  best_nll = 1000.\n",
    "  patience = 0\n",
    "\n",
    "  # Main training loop\n",
    "  for e in range(num_epochs):\n",
    "    model.train() # set the model to the training mode\n",
    "    # load batches\n",
    "    for indx_batch, (batch, targets) in enumerate(training_loader):\n",
    "      # calculate the forward pass (loss function for given images and labels)\n",
    "      loss = model.forward(batch, targets)\n",
    "      # remember we need to zero gradients! Just in case!\n",
    "      optimizer.zero_grad()\n",
    "      # calculate backward pass\n",
    "      loss.backward(retain_graph=True)\n",
    "      # run the optimizer\n",
    "      optimizer.step()\n",
    "\n",
    "    # Validation: Evaluate the model on the validation data\n",
    "    loss_e, error_e = evaluation(val_loader, model_best=model, epoch=e)\n",
    "    nll_val.append(loss_e)  # save for plotting\n",
    "    error_val.append(error_e)  # save for plotting\n",
    "\n",
    "    # Early-stopping: update the best performing model and break training if no \n",
    "    # progress is observed.\n",
    "    if e == 0:\n",
    "      torch.save(model, name + '.model')\n",
    "      best_nll = loss_e\n",
    "    else:\n",
    "      if loss_e < best_nll:\n",
    "        torch.save(model, name + '.model')\n",
    "        best_nll = loss_e\n",
    "        patience = 0\n",
    "      else:\n",
    "        patience = patience + 1\n",
    "\n",
    "    if patience > max_patience:\n",
    "      break\n",
    "\n",
    "  # Return nll and classification error.\n",
    "  nll_val = np.asarray(nll_val)\n",
    "  error_val = np.asarray(error_val)\n",
    "\n",
    "  return nll_val, error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHYGz3G87nuk"
   },
   "source": [
    "### 2.4 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op-YbN-JREqw"
   },
   "source": [
    "#### Initialize dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "R_cRaP3gRET1"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Initialize training, validation and test sets.\n",
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "# Initialize data loaders.\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3ni_8Pv3iuG"
   },
   "source": [
    "#### Initialize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "dnMs4gcLRLEK"
   },
   "outputs": [],
   "source": [
    "# PLEASE DO NOT REMOVE\n",
    "# Hyperparameters\n",
    "# -> data hyperparams\n",
    "D = 64   # input dimension\n",
    "\n",
    "# -> model hyperparams\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "K = 10 # the number of labels\n",
    "num_kernels = 32 #the number of kernels for CNN\n",
    "\n",
    "# -> training hyperparams\n",
    "lr = 1e-3 # learning rate\n",
    "wd = 1e-5 # weight decay\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VDyHP173vLF"
   },
   "source": [
    "#### Running experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9T9nXcE3xF2"
   },
   "source": [
    "In the code below, you are supposed to implement architectures for MLP and CNN. For properly implementing these architectures, you can get 0.5pt for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "AZH7ahwBRP9B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> START classifier_mlp\n",
      "Epoch: 0, val nll=2.3879688807896207, val ce=1.0\n",
      "Epoch: 10, val nll=0.6324454879760742, val ce=1.0\n",
      "Epoch: 20, val nll=0.3440612806592669, val ce=1.0\n",
      "Epoch: 30, val nll=0.2554517010280064, val ce=1.0\n",
      "Epoch: 40, val nll=0.21069958686828613, val ce=1.0\n",
      "Epoch: 50, val nll=0.17962463787623814, val ce=1.0\n",
      "Epoch: 60, val nll=0.16092028958456858, val ce=1.0\n",
      "Epoch: 70, val nll=0.15076474394117084, val ce=1.0\n",
      "Epoch: 80, val nll=0.14157884189060757, val ce=1.0\n",
      "Epoch: 90, val nll=0.13224412509373257, val ce=1.0\n",
      "Epoch: 100, val nll=0.1264686417579651, val ce=1.0\n",
      "Epoch: 110, val nll=0.12191512141908918, val ce=1.0\n",
      "Epoch: 120, val nll=0.11755252259118217, val ce=1.0\n",
      "Epoch: 130, val nll=0.11561017411095756, val ce=1.0\n",
      "Epoch: 140, val nll=0.11348185982022967, val ce=1.0\n",
      "Epoch: 150, val nll=0.1101046643938337, val ce=1.0\n",
      "Epoch: 160, val nll=0.11100831849234445, val ce=1.0\n",
      "Epoch: 170, val nll=0.10887375967843192, val ce=1.0\n",
      "-> FINAL PERFORMANCE: nll=0.369535686185696, ce=1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> START classifier_cnn\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "view() argument after * must be an iterable, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-0a88035b74c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                                 \u001b[0mtraining_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                 val_loader=val_loader)\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;31m# The final evaluation (on the test set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-a1b13c8573fe>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;31m# calculate the forward pass (loss function for given images and labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0;31m# remember we need to zero gradients! Just in case!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-3f314cd3142f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, reduction)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;31m#------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m# PLEASE FILL IN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaia/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaia/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gaia/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d96cb39776cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# This module flattens an input (tensor -> matrix) by blending dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: view() argument after * must be an iterable, not int"
     ]
    }
   ],
   "source": [
    "# PLEASE DO NOT REMOVE and FILL IN WHEN NECESSARY!\n",
    "# We will run two models: MLP and CNN\n",
    "names = ['classifier_mlp', 'classifier_cnn']\n",
    "\n",
    "# loop over models\n",
    "for name in names:\n",
    "  print('\\n-> START {}'.format(name))\n",
    "  # Create a folder (REMEMBER: You must mount your drive if you use Colab!)\n",
    "  if name == 'classifier_mlp':\n",
    "    name = name + '_M_' + str(M)\n",
    "  elif name == 'classifier_cnn':\n",
    "    name = name + '_M_' + str(M) + '_kernels_' + str(num_kernels)\n",
    "  \n",
    "  # Create a folder if necessary\n",
    "  result_dir = os.path.join(results_dir, 'results', name + '/')\n",
    "  if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "  # MLP\n",
    "  if name[0:14] == 'classifier_mlp':\n",
    "    #=========\n",
    "    # GRADING: \n",
    "    # 0\n",
    "    # 0.5pt if properly implemented\n",
    "    #=========\n",
    "    #------\n",
    "    # PLEASE FILL IN:\n",
    "    # classnet = nn.Sequential(...)\n",
    "    #\n",
    "    # You are asked here to propose your own architecture\n",
    "    # NOTE: Please remember that the output must be LogSoftmax!\n",
    "    classnet = nn.Sequential(\n",
    "                              nn.Linear(D,32),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Linear(32,K),\n",
    "                              nn.LogSoftmax(dim=1)\n",
    "\n",
    "    )\n",
    "                          \n",
    "    #------\n",
    "\n",
    "  # CNN\n",
    "  elif name[0:14] == 'classifier_cnn':\n",
    "\n",
    "    #=========\n",
    "    # GRADING: \n",
    "    # 0\n",
    "    # 0.5pt if properly implemented\n",
    "    #=========\n",
    "    #------\n",
    "    # PLEASE FILL IN:\n",
    "    classnet = nn.Sequential(\n",
    "                        Reshape(?), \n",
    "#                         nn.Conv2d(64, 18, kernel_size=num_kernels, stride=1, padding=1),\n",
    "#                         nn.MaxPool2d(kernel_size=num_kernels, stride=2, padding=0),\n",
    "                        Flatten(),\n",
    "                        nn.Linear(D,32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32,K),,\n",
    "                        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "\n",
    "            \n",
    "\n",
    "    #\n",
    "    # You are asked here to propose your own architecture\n",
    "    # NOTE: Plese note that the images are represented as vectors, thus, you must\n",
    "    # use Reshape(size) as the first layer, and Flatten() after all convolutional\n",
    "    # layers and before linear layers.\n",
    "    # NOTE: Please remember that the output must be LogSoftmax!\n",
    "    #------\n",
    "\n",
    "  # Init ClassifierNN\n",
    "  model = ClassifierNeuralNet(classnet)\n",
    "\n",
    "  # Init OPTIMIZER (here we use ADAMAX)\n",
    "  optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr, weight_decay=wd) \n",
    "  \n",
    "  # Training procedure\n",
    "  nll_val, error_val = training(name=result_dir + name,\n",
    "                                max_patience=max_patience,\n",
    "                                num_epochs=num_epochs,\n",
    "                                model=model,\n",
    "                                optimizer=optimizer,\n",
    "                                training_loader=training_loader,\n",
    "                                val_loader=val_loader)\n",
    "  \n",
    "  # The final evaluation (on the test set)\n",
    "  test_loss, test_error = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "  # write the results to a file\n",
    "  f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "  f.write('NLL: ' + str(test_loss) + '\\nCE: ' + str(test_error))\n",
    "  f.close()\n",
    "  # create curves\n",
    "  plot_curve(result_dir + name, nll_val, file_name='_nll_val_curve.pdf', ylabel='nll', test_eval=test_loss)\n",
    "  plot_curve(result_dir + name, error_val, file_name='_ca_val_curve.pdf', ylabel='ce', color='r-', test_eval=test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFX-DzH9ftPg"
   },
   "source": [
    "## 2.5 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-TFtGdZfz3a"
   },
   "source": [
    "**Question 3 (0-0.5pt)**: Please compare the convergence of MLP and CNN in terms of the loss function and the classification error.\n",
    "\n",
    "**Answer**: PLEASE FILL IN and PASTE THE IMAGES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f2P57ZmlwXz"
   },
   "source": [
    "**Question 4 (0-0.5pt)**: In general, for a properly picked architectures, a CNN should work better than an MLP. Did you notice that? Why (in general) CNNs are better suited to images than MLPs?\n",
    "\n",
    "**Answer**: PLEASE FILL IN and PASTE THE IMAGES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QJ_mRdT7Ais"
   },
   "source": [
    "## 3 Application to Street House View Numbers (SVHN) (6pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHhUUaYL7GEx"
   },
   "source": [
    "Please repeat (some) of the code in the previous section and apply a bigger convolutional neural network (CNN) to the following dataset:\n",
    "\n",
    "http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Please follow the following steps:\n",
    "1. (1pt) Create appropriate Dataset class. Please remember to use the original training data and test data, and also to create a validation set from the traning data (at least 10% of the training examples). **Do not use extra examples!**\n",
    "2. (1pt) Implement an architecture that will give at most 0.1 classification error. For instance, see this paper as a reference: https://arxiv.org/pdf/1204.3968.pdf#:~:text=The%20SVHN%20classification%20dataset%20%5B8,set%20of%20more%20difficult%20samples\n",
    "3. (1pt) Think of an extra component that could improve the performance (e.g., a regularization, specific activation functions).\n",
    "4. (1pt) Provide a good explanation of the applied architecture and a description of all components.\n",
    "5. (2pt) Analyze the results.\n",
    "\n",
    "**Please be very precise, comment your code and provide a comprehensive and clear analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
